{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39505ad6",
   "metadata": {},
   "source": [
    "We have created the GPT model and downloaded the weights from the GPT2 model into our model. Now, it is pre-trained but does not generate related text to what we say, so in order to make the model specialized we are going to finetune the model on a data. I want to create my own model but in order to understand how we finetune exactly, i am going to follow the steps given in the book exactly, and then if time permits i will finetune it on a dataset i like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dff6a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import tiktoken\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "003958b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sms_spam_collection/SMSSpamCollection.tsv already exists. Skipping download and extraction.\n"
     ]
    }
   ],
   "source": [
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"sms_spam_collection.zip\"\n",
    "extracted_path = \"sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
    "    if data_file_path.exists():\n",
    "        print(f\"{data_file_path} already exists. Skipping download and extraction.\")\n",
    "        return\n",
    "\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        with open(zip_path, \"wb\") as out_file:\n",
    "            out_file.write(response.read())\n",
    "\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extracted_path)\n",
    "\n",
    "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
    "    os.rename(original_file_path, data_file_path)\n",
    "    print(f\"File downloaded and saved as {data_file_path}\")\n",
    "\n",
    "try:\n",
    "    download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n",
    "except (urllib.error.HTTPError, urllib.error.URLError, TimeoutError) as e:\n",
    "    print(f\"Primary URL failed: {e}. Trying backup URL...\")\n",
    "    url = \"https://f001.backblazeb2.com/file/LLMs-from-scratch/sms%2Bspam%2Bcollection.zip\"\n",
    "    download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b93a503c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                               Text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57f299a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbabcb93",
   "metadata": {},
   "source": [
    "The number of non spam msgs are way higher than the spam ones, this would create a bias towards the non spam ones and the model might not be as good as detecting spam msgs. So, we will make the dataset balanced. This is a very important step, we must preprocess any kind of data before training or fine tuning a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c4a1dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     747\n",
       "spam    747\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_balanced_dataset(df):\n",
    "    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n",
    "    ham_subset = df[df[\"Label\"] == \"ham\"].sample(num_spam, random_state=109)\n",
    "    balanced_df = pd.concat([ham_subset, df[df[\"Label\"] == \"spam\"]])\n",
    "    return balanced_df\n",
    "\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "balanced_df[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f1dbff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4882</th>\n",
       "      <td>0</td>\n",
       "      <td>When/where do I pick you up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3715</th>\n",
       "      <td>0</td>\n",
       "      <td>Oh, i will get paid. The most outstanding one ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>0</td>\n",
       "      <td>Yeah you should. I think you can use your gt a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1657</th>\n",
       "      <td>0</td>\n",
       "      <td>Yes I posted a couple of pics on fb. There's s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4245</th>\n",
       "      <td>0</td>\n",
       "      <td>Aight, I'm chillin in a friend's room so text ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5537</th>\n",
       "      <td>1</td>\n",
       "      <td>Want explicit SEX in 30 secs? Ring 02073162414...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5540</th>\n",
       "      <td>1</td>\n",
       "      <td>ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5547</th>\n",
       "      <td>1</td>\n",
       "      <td>Had your contract mobile 11 Mnths? Latest Moto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>1</td>\n",
       "      <td>REMINDER FROM O2: To get 2.50 pounds free call...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>1</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1494 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label                                               Text\n",
       "4882      0                        When/where do I pick you up\n",
       "3715      0  Oh, i will get paid. The most outstanding one ...\n",
       "220       0  Yeah you should. I think you can use your gt a...\n",
       "1657      0  Yes I posted a couple of pics on fb. There's s...\n",
       "4245      0  Aight, I'm chillin in a friend's room so text ...\n",
       "...     ...                                                ...\n",
       "5537      1  Want explicit SEX in 30 secs? Ring 02073162414...\n",
       "5540      1  ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...\n",
       "5547      1  Had your contract mobile 11 Mnths? Latest Moto...\n",
       "5566      1  REMINDER FROM O2: To get 2.50 pounds free call...\n",
       "5567      1  This is the 2nd time we have tried 2 contact u...\n",
       "\n",
       "[1494 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})    \n",
    "balanced_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37df4669",
   "metadata": {},
   "source": [
    "Now lets split the data into random sets of train, val and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c06ea41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/salaj/anaconda3/envs/dl-env/lib/python3.10/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def split_rand(df, train_fx, val_fx):\n",
    "    df = df.sample(frac = 1, random_state=109).reset_index(drop=True)\n",
    "    \n",
    "    train_end = int(len(df) * train_fx)\n",
    "    val_end = train_end + int(len(df)*val_fx)\n",
    "    \n",
    "    train_df = df[:train_end]\n",
    "    val_df = df[train_end:val_end]\n",
    "    test_df = df[val_end:]\n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "train_df, val_df, test_df = split_rand(balanced_df, 0.7, 0.1)\n",
    "\n",
    "train_df.to_csv(\"train.csv\", index=None)\n",
    "val_df.to_csv(\"val.csv\", index=None)\n",
    "test_df.to_csv(\"test.csv\", index=None)\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1db354d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpamDataset(Dataset):\n",
    "    def __init__(self, csv, tokenizer,max_lenght = None, pad_token_id = 50256):\n",
    "        self.data = pd.read_csv(csv)\n",
    "        self.encoded_txt = [tokenizer.encode(txt) for txt in self.data[\"Text\"]]\n",
    "        if max_lenght is None :\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "        else:\n",
    "            self.max_length = max_lenght\n",
    "            self.encoded_txt = [encoded_text[:self.max_length]\n",
    "                                for encoded_text in self.encoded_txt]\n",
    "        \n",
    "        self.encoded_txt = [\n",
    "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
    "            for encoded_text in self.encoded_txt\n",
    "        ]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        encoded = self.encoded_txt[index]\n",
    "        label = self.data.iloc[index][\"Label\"]\n",
    "        return (\n",
    "            torch.tensor(encoded, dtype=torch.long),\n",
    "            torch.tensor(label, dtype=torch.long)\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def _longest_encoded_length(self):\n",
    "        max_length = 0\n",
    "        for encoded_text in self.encoded_txt:\n",
    "            encoded_length = len(encoded_text)\n",
    "            if encoded_length > max_length:\n",
    "                max_length = encoded_length\n",
    "        return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d51b1530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = SpamDataset(csv=\"train.csv\", max_lenght=None, tokenizer=tokenizer)\n",
    "val_dataset = SpamDataset(csv=\"val.csv\", max_lenght=train_dataset.max_length, tokenizer=tokenizer)\n",
    "test_dataset = SpamDataset(csv=\"test.csv\", max_lenght=train_dataset.max_length, tokenizer=tokenizer)\n",
    "train_dataset.max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb5a208d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 19 38\n"
     ]
    }
   ],
   "source": [
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "print(len(train_loader), len(val_loader), len(test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db865fe6",
   "metadata": {},
   "source": [
    " Now we will initialize the pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30c869b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from important_GPT_blocks import download_weights\n",
    "download_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe48ec47",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "assert train_dataset.max_length <= BASE_CONFIG[\"context_length\"], (\n",
    "    f\"Dataset length {train_dataset.max_length} exceeds model's context \"\n",
    "    f\"length {BASE_CONFIG['context_length']}. Reinitialize data sets with \"\n",
    "    f\"`max_length={BASE_CONFIG['context_length']}`\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6177a2cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/124M/encoder.json\n",
      "File already exists and is up-to-date: gpt2/124M/hparams.json\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "from important_GPT_blocks import GPTModel\n",
    "from load_weights import load_weights_into_gpt\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59795bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With great power comes great power, and the only way to get it, the first time I saw\n"
     ]
    }
   ],
   "source": [
    "from add_training_data import text_to_token_ids, token_ids_to_text\n",
    "from important_GPT_blocks import simple_text_gen\n",
    "\n",
    "text_1 = \"With great power comes great\"\n",
    "\n",
    "token_ids = simple_text_gen(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_1, tokenizer),\n",
    "    max_tokens=15,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "344cb4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
      "\n",
      "'The first time I was in the office of the 'C' and 'I' said to me\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
    "    \" 'You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.'\"\n",
    ")\n",
    "token_ids = simple_text_gen(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_2, tokenizer),\n",
    "    max_tokens=23,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300237ca",
   "metadata": {},
   "source": [
    "So now the model has dowanloaded the gpt2 model and is using it to generate text, we just need to add a classification head and train it to classify the messages as spam or ham."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6662dc38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "052c8298",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "torch.manual_seed(123)\n",
    "num_classes = 2\n",
    "model.out_head = torch.nn.Linear(in_features=BASE_CONFIG[\"emb_dim\"], out_features=num_classes)\n",
    "\n",
    "for param in model.trf_blocks[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.final_norm.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "518b8f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1858,  373,  257, 3516, 3706]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer.encode(\"There was a guy named\")\n",
    "inputs = torch.tensor(inputs).unsqueeze(0)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90231b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.6904,  1.1111],\n",
       "         [-1.6895,  5.3574],\n",
       "         [-3.0605,  5.0846],\n",
       "         [-2.7163,  4.8241],\n",
       "         [-2.6445,  3.8505]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    output = model(inputs)\n",
    "    \n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02118ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[:, -1, :]\n",
    "label = torch.argmax(output[:,-1,:])\n",
    "label.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f0ef898",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
    "    model.eval()\n",
    "    correct_predictions, num_examples = 0, 0\n",
    "\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
    "            predicted_labels = torch.argmax(logits, dim=-1)\n",
    "\n",
    "            num_examples += predicted_labels.shape[0]\n",
    "            correct_predictions += (predicted_labels == target_batch).sum().item()\n",
    "        else:\n",
    "            break\n",
    "    return correct_predictions / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4bdf953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 47.50%\n",
      "Validation accuracy: 50.00%\n",
      "Test accuracy: 52.50%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device) \n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c39dc5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)[:, -1, :] \n",
    "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "    return loss\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a37e3604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 3.274\n",
      "Validation loss: 2.936\n",
      "Test loss: 3.067\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "    test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
    "\n",
    "print(f\"Training loss: {train_loss:.3f}\")\n",
    "print(f\"Validation loss: {val_loss:.3f}\")\n",
    "print(f\"Test loss: {test_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de16b37",
   "metadata": {},
   "source": [
    "Till now we have seen that the loss is high and the accuracy is low. This is because we have not fine tuned the model yet. Basically, we stoppped the gradient descent and disallowed the model to train its weights, then applied a classification head which had only 2 outputs, spam or not spam rather than 50257 outputs like earlier. THen unfreezing the bottom layers to make the model working again, the model is working well now it can understand the text and is able to classify into two categories, its just that it has not been taught which are spam and which arent. So, now we will train/fine tune it, for that we will use cross entropy loss because classification is a boolean property in terms of our problem, so we won't be able to define a loss function as it wont be differentiable. Thus, instead we use the cross-entropy loss considering 1 as the spam and 0 as non spam and compute the loss accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "10c14d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                            eval_freq, eval_iter):\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "    examples_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train() \n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() \n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step() \n",
    "            examples_seen += input_batch.shape[0]\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
    "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "\n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b67630d",
   "metadata": {},
   "source": [
    "These above functions are similar to the ones we defined in chapter 5 while training our GPT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "73ba0567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 0.135, Val loss 0.272\n",
      "Ep 1 (Step 000050): Train loss 0.269, Val loss 0.190\n",
      "Ep 1 (Step 000100): Train loss 0.155, Val loss 0.177\n",
      "Training accuracy: 95.00% | Validation accuracy: 92.50%\n",
      "Ep 2 (Step 000150): Train loss 0.078, Val loss 0.162\n",
      "Ep 2 (Step 000200): Train loss 0.205, Val loss 0.172\n",
      "Ep 2 (Step 000250): Train loss 0.087, Val loss 0.165\n",
      "Training accuracy: 95.00% | Validation accuracy: 95.00%\n",
      "Ep 3 (Step 000300): Train loss 0.093, Val loss 0.218\n",
      "Ep 3 (Step 000350): Train loss 0.201, Val loss 0.271\n",
      "Training accuracy: 97.50% | Validation accuracy: 97.50%\n",
      "Ep 4 (Step 000400): Train loss 0.013, Val loss 0.106\n",
      "Ep 4 (Step 000450): Train loss 0.022, Val loss 0.106\n",
      "Ep 4 (Step 000500): Train loss 0.007, Val loss 0.103\n",
      "Training accuracy: 97.50% | Validation accuracy: 97.50%\n",
      "Ep 5 (Step 000550): Train loss 0.262, Val loss 0.163\n",
      "Ep 5 (Step 000600): Train loss 0.016, Val loss 0.103\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Ep 6 (Step 000650): Train loss 0.016, Val loss 0.132\n",
      "Ep 6 (Step 000700): Train loss 0.045, Val loss 0.085\n",
      "Ep 6 (Step 000750): Train loss 0.031, Val loss 0.095\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Ep 7 (Step 000800): Train loss 0.014, Val loss 0.086\n",
      "Ep 7 (Step 000850): Train loss 0.010, Val loss 0.091\n",
      "Ep 7 (Step 000900): Train loss 0.024, Val loss 0.135\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Ep 8 (Step 000950): Train loss 0.001, Val loss 0.097\n",
      "Ep 8 (Step 001000): Train loss 0.028, Val loss 0.158\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Ep 9 (Step 001050): Train loss 0.012, Val loss 0.099\n",
      "Ep 9 (Step 001100): Train loss 0.008, Val loss 0.104\n",
      "Ep 9 (Step 001150): Train loss 0.010, Val loss 0.166\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Ep 10 (Step 001200): Train loss 0.025, Val loss 0.083\n",
      "Ep 10 (Step 001250): Train loss 0.012, Val loss 0.185\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Training completed in 2.70 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fc74d436",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
    "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2 = ax1.twiny()  \n",
    "    ax2.plot(examples_seen, train_values, alpha=0)  \n",
    "    ax2.set_xlabel(\"Examples seen\")\n",
    "\n",
    "    fig.tight_layout() \n",
    "    plt.savefig(f\"{label}-plot.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bee5ff24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_accs))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_accs))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_accs, val_accs, label=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fc1ee91e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 99.90%\n",
      "Validation accuracy: 96.64%\n",
      "Test accuracy: 96.67%\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d135fd82",
   "metadata": {},
   "source": [
    "training for 10 epochs rather than 5 trained it much better, highly increasing the accuracy. Now i will use the test cases given in the book as it is, to test the model and then later try my own statments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5ff080f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_review(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n",
    "    model.eval()\n",
    "\n",
    "    # Prepare inputs to the model\n",
    "    input_ids = tokenizer.encode(text)\n",
    "    supported_context_length = model.pos_emb.weight.shape[0]\n",
    "    input_ids = input_ids[:min(max_length, supported_context_length)]\n",
    "    assert max_length is not None, (\n",
    "        \"max_length must be specified. If you want to use the full model context, \"\n",
    "        \"pass max_length=model.pos_emb.weight.shape[0].\"\n",
    "    )\n",
    "    assert max_length <= supported_context_length, (\n",
    "        f\"max_length ({max_length}) exceeds model's supported context length ({supported_context_length}).\"\n",
    "    )    \n",
    "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
    "    input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0) # add batch dimension\n",
    "\n",
    "    # Model inference\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_tensor)[:, -1, :]  # Logits of the last output token\n",
    "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "    # Return the classified result\n",
    "    return \"spam\" if predicted_label == 1 else \"not spam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "14af05f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n"
     ]
    }
   ],
   "source": [
    "text_1 = (\n",
    "    \"You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_1, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9a257d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not spam\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Hey, just wanted to check if we're still on\"\n",
    "    \" for dinner tonight? Let me know!\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2f2d798b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Let's meet for a date and discuss the opportunity further\"\n",
    "    \"You have won the gift and will recieve a prize\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b8b09dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"review_classifier.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2d2148",
   "metadata": {},
   "source": [
    "Works amazinglyy!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dl-env)",
   "language": "python",
   "name": "dl-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
