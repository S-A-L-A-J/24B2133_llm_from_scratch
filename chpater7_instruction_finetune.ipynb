{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d67354d7",
   "metadata": {},
   "source": [
    "In the last chapter we used a classification head to finetune our llm to classify statements into spam or non-spam, now we will finetune it to follow instructions and provide responses accordingly. For that we need a dataset, then load the model with that dataset and train it. Firstly i am training the same way it is given in the module, then later on i will train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "604aeb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports \n",
    "\n",
    "import json\n",
    "import os\n",
    "import urllib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c97a85d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1100"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file :\n",
    "        data = json.load(file)\n",
    "        \n",
    "    return data\n",
    "\n",
    "file_path = \"instruction-data.json\"\n",
    "data = load_file(file_path)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "288d7528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': 'Alter the content of the sentence to use the past tense.', 'input': 'The ship sails at dawn.', 'output': 'The ship sailed at dawn.'}\n",
      "{'instruction': \"Generate a sentence that follows the pattern: 'Rarely do I _____'\", 'input': '', 'output': 'Rarely do I eat fast food.'}\n",
      "{'instruction': \"Generate a sentence using the word 'gregarious'.\", 'input': '', 'output': 'He was gregarious, making friends wherever he went.'}\n"
     ]
    }
   ],
   "source": [
    "print(data[30])\n",
    "print(data[31])\n",
    "print(data[40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb9b4eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d16a8ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Alter the content of the sentence to use the past tense.\n",
      "\n",
      "### Input:\n",
      "The ship sails at dawn.\n",
      "\n",
      "###Response :\n",
      "The ship sailed at dawn.\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[30])\n",
    "desired_response = f\"\\n\\n###Response :\\n{data[30]['output']}\"\n",
    "\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3131841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "935 110 55\n"
     ]
    }
   ],
   "source": [
    "train_portion = int(len(data) * 0.85)\n",
    "test_portion = int(len(data) * 0.10)\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:test_portion+train_portion]\n",
    "val_data = data[test_portion + train_portion:]\n",
    "\n",
    "print(len(train_data), len(test_data), len(val_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c35141",
   "metadata": {},
   "source": [
    "Now to batch this data, we will format the data using prompt template then tokenize the formatted data, followed by padding to adjust the same size, creating target token ids for training and replace the padding tokens with place holders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3aaf4806",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.encoded_texts = []\n",
    "        \n",
    "        for entry in data:\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(\n",
    "                tokenizer.encode(full_text)\n",
    "            )\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79445ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2fa64e",
   "metadata": {},
   "source": [
    "For the padding, we will not decide a maximum length for all the batches and tokens, instead we can create a custom collate function which pads the training examples in each batch to have the same length but different batches can have different lengths, this way there won't be unnecessary long examples for all the batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b924b4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_draft1(batch, pad_token_id = 50256, device = \"cpu\"):\n",
    "    batch_max = max(len(item)+1 for item in batch)\n",
    "    inputs_list = []\n",
    "    for item in batch :\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] * (batch_max - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        inputs_list.append(inputs)\n",
    "    \n",
    "    inputs_tensor = torch.stack(inputs_list).to(device)\n",
    "    return inputs_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0bf70d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")\n",
    "\n",
    "print(custom_collate_draft1(batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ae093d",
   "metadata": {},
   "source": [
    "The highest input length was 5, so for inputs 2 and 3 padded tokens were added to make the length equal to 5, but for a different batch whose max length would be 4 then it would be only padded to 4. For the training of an LLM we need shfited tokens too, so we add that and also add an ignore_index parameter to replace all the padding tokens with a new value so that these tokens are ignored by the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b415c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fxn(batch, pad_token_id = 50256, ignore_index = -100, allowed_max_length = None, device = \"cpu\"):\n",
    "    batch_max = max(len(item)+1 for item in batch)\n",
    "    inputs_list, targets_list = [], []\n",
    "    for item in batch :\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "        padded = (new_item + [pad_token_id] * (batch_max - len(new_item)))\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        targets = torch.tensor(padded[1:])\n",
    "        \n",
    "        mask = targets == pad_token_id\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = ignore_index\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "\n",
    "        inputs_list.append(inputs)\n",
    "        targets_list.append(targets)\n",
    "\n",
    "    inputs_tensor = torch.stack(inputs_list).to(device)\n",
    "    targets_tensor = torch.stack(targets_list).to(device)\n",
    "\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3af60d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256,  -100,  -100,  -100],\n",
      "        [    8,     9, 50256,  -100,  -100]])\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = custom_collate_fxn(batch)\n",
    "\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "586f048a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n"
     ]
    }
   ],
   "source": [
    "logits_1 = torch.tensor(\n",
    "    [[-1.0, 1.0],  # 1st training example\n",
    "     [-0.5, 1.5]]  # 2nd training example\n",
    ")\n",
    "targets_1 = torch.tensor([0, 1])\n",
    "\n",
    "\n",
    "loss_1 = torch.nn.functional.cross_entropy(logits_1, targets_1)\n",
    "print(loss_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12bc467e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7936)\n"
     ]
    }
   ],
   "source": [
    "logits_2 = torch.tensor(\n",
    "    [[-1.0, 1.0],\n",
    "     [-0.5, 1.5],\n",
    "     [-0.5, 1.5]]  # New 3rd training example\n",
    ")\n",
    "targets_2 = torch.tensor([0, 1, 1])\n",
    "\n",
    "loss_2 = torch.nn.functional.cross_entropy(logits_2, targets_2)\n",
    "print(loss_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3f3ff3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n",
      "loss_1 == loss_3: tensor(True)\n"
     ]
    }
   ],
   "source": [
    "targets_3 = torch.tensor([0, 1, -100])\n",
    "\n",
    "loss_3 = torch.nn.functional.cross_entropy(logits_2, targets_3)\n",
    "print(loss_3)\n",
    "print(\"loss_1 == loss_3:\", loss_1 == loss_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e36368f",
   "metadata": {},
   "source": [
    "What we see here, adding of -100 token to the targets doesn't change the loss this is because in the internal structure of cross entropy toekns with -100 value are ignored for the loss calculation. So, for the first padding token we use 50256 just to indicate that the sequence has ended and then all the tokens are -100 so that their loss isn't counted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fb8959c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "519953a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "customized_collate_fxn = partial(\n",
    "    custom_collate_fxn,\n",
    "    device=device,\n",
    "    allowed_max_length=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39a4a79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fxn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fxn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fxn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39573db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 89]) torch.Size([8, 89])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 88]) torch.Size([8, 88])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef3dde22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 30003,  6525,   262,  6827,  1262,   257,\n",
      "          985,   576,    13,   198,   198, 21017, 23412,    25,   198,   464,\n",
      "         5156,   318,   845, 13779,    13,   198,   198, 21017, 18261,    25,\n",
      "          198,   464,  5156,   318,   355, 13779,   355,   257,  4936,    13,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
      "       device='cuda:0')\n",
      "tensor([  318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
      "         2882,   326, 20431, 32543,   262,  2581,    13,   198,   198, 21017,\n",
      "        46486,    25,   198, 30003,  6525,   262,  6827,  1262,   257,   985,\n",
      "          576,    13,   198,   198, 21017, 23412,    25,   198,   464,  5156,\n",
      "          318,   845, 13779,    13,   198,   198, 21017, 18261,    25,   198,\n",
      "          464,  5156,   318,   355, 13779,   355,   257,  4936,    13, 50256,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(inputs[0])\n",
    "print(targets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a98b5f6",
   "metadata": {},
   "source": [
    "Now we will load the pretrained gpt2 model , but this time we are going to load the medium sized model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c5d9870",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/salaj/anaconda3/envs/dl-env/lib/python3.10/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "from important_GPT_blocks import GPTModel, load_weights_into_gpt\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=model_size,\n",
    "    models_dir=\"gpt2\"\n",
    ")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ed814b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "input_text = format_input(val_data[0])\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10453a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "    for _ in range(max_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "        if top_k is not None:\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
    "\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)  \n",
    "            idx_next = torch.multinomial(probs, num_samples=1) \n",
    "\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True) \n",
    "            \n",
    "        if idx_next == eos_id:  \n",
    "            break\n",
    "        idx = torch.cat((idx, idx_next), dim=1) \n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e16c5aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from add_training_data import text_to_token_ids, token_ids_to_text\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(input_text, tokenizer),\n",
    "    max_tokens=35,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    "    eos_id=50256,\n",
    ")\n",
    "generated_text = token_ids_to_text(token_ids, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c7f3e967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a list of the following:\n",
      "\n",
      "The first time I was in the kitchen of my first job. I was a little surprised to see that the\n"
     ]
    }
   ],
   "source": [
    "response_text = (\n",
    "    generated_text[len(input_text):]\n",
    "    .replace(\"### Response:\", \"\")\n",
    "    .strip()\n",
    ")\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0de83ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)[:, -1, :] \n",
    "    target_batch = target_batch[:, -1]\n",
    "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "    return loss\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a0497246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.529736948013306\n",
      "4.704107332229614\n"
     ]
    }
   ],
   "source": [
    "from add_training_data import train_model_simple\n",
    "\n",
    "model.to(device)\n",
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "    \n",
    "print(train_loss)\n",
    "print(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d0a5abc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.ipc_collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "718e382a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000115): Train loss 0.604, Val loss 0.818\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The chef cooks the meal every day.<|endoftext|>The following is an excerpt from 'The Great Gatsby': A History of the United States of America.'  The Great Gatsby The Great Gatsby\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal every day is cooked by the chef.<|endoftext|>The following is an excerpt from 'The Great Gatsby': The Great Gatsby  The Great Gatsby The Great Gatsby The\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal every day is cooked by the chef.<|endoftext|>The following is an excerpt from 'The Great Gatsby': A History of the United Kingdom.'  'The Great Gatsby' is a fictional novel\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal every day is cooked by the chef every day.<|endoftext|>The following is an excerpt from 'The Great Gatsby': A Memoir'.  'The Great Gatsby' was written by a man\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal every day by the chef is cooked by the chef every day.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Input: Cut the fruit\n",
      "Ep 6 (Step 000695): Train loss 0.193, Val loss 0.844\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal every day by the chef cooks the meal every day.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Response: The cookies on the table\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal every day is cooked by the chef every day.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Input: The chef cooked the meal every\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal every day is cooked by the chef every day.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Input: Cut the fruit  ###\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal every day is prepared by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Input: Cut the fruit  ### Response:\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal every day is prepared by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Input: The chef cooked the meal every day.\n",
      "Training completed in 8.66 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9335a19",
   "metadata": {},
   "source": [
    "I tried to train the gpt medium model but the Cuda storage it needs exceed 4.5 gb or so, my gpu only has 3.8 GB VRAM so it is not possible. I tried using different parameters like batch size 1, tweaking the optimizer and etc but nothing works, so i need to train it on the gpt small itself. Later i might try to use the google colab to train medium or maybe large but as far as this project goes, i will train only the gpt small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "37e9eb6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  \n",
    "    \n",
    "    ax2 = ax1.twiny() \n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0) \n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5ab1a4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a simile.\n",
      "\n",
      "### Input:\n",
      "The car is very fast.\n",
      "\n",
      "Correct response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a cheetah.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What type of cloud is typically associated with thunderstorms?\n",
      "\n",
      "Correct response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> The type of cloud typically associated with thunderstorms is cirrus.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Name the author of 'Pride and Prejudice'.\n",
      "\n",
      "Correct response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the periodic symbol for chlorine?\n",
      "\n",
      "Correct response:\n",
      ">> The periodic symbol for chlorine is Cl.\n",
      "\n",
      "Model response:\n",
      ">> The periodic symbol for chlorine is CHlorb.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Correct the punctuation in the sentence.\n",
      "\n",
      "### Input:\n",
      "Its time to go home.\n",
      "\n",
      "Correct response:\n",
      ">> The corrected sentence should be: 'It's time to go home.'\n",
      "\n",
      "Model response:\n",
      ">> The corrected sentence should be: 'Time to go home.'\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence.\n",
      "\n",
      "### Input:\n",
      "The lecture was delivered in a clear manner.\n",
      "\n",
      "Correct response:\n",
      ">> The lecture was delivered clearly.\n",
      "\n",
      "Model response:\n",
      ">> The speech was clearly given.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Generate a humorous anecdote.\n",
      "\n",
      "Correct response:\n",
      ">> Why was the math book sad? Because it had too many problems!\n",
      "\n",
      "Model response:\n",
      ">> The humorous anecdote was written by the author.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Identify the correct spelling: 'recieve' or 'receive'.\n",
      "\n",
      "Correct response:\n",
      ">> The correct spelling is 'receive'.\n",
      "\n",
      "Model response:\n",
      ">> The correct spelling is 'recieve'.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Create a sentence using the word 'nostalgia'.\n",
      "\n",
      "Correct response:\n",
      ">> Nostalgia washed over her as she looked through the old photos.\n",
      "\n",
      "Model response:\n",
      ">> Her Nostalgia for the Present Day is a strong need.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Classify the following numbers as prime or composite.\n",
      "\n",
      "### Input:\n",
      ": 11, 14, 19.\n",
      "\n",
      "Correct response:\n",
      ">> Prime numbers: 11, 19\n",
      "Composite numbers: 14\n",
      "\n",
      "Model response:\n",
      ">> Prime numbers: 11, 14, 19\n",
      "Composite numbers: 19, 11, 14\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "\n",
    "for entry in test_data[:10]:\n",
    "\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    ")\n",
    "\n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "    print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9524798a",
   "metadata": {},
   "source": [
    "THe model is performing well, however it is still making some errors. In the code implemented in the book, the word cumulonimbus may have come up in the training of the gpt medium but the gpt small may not know the usage, there i think it went bad. I will try some of my own questions to test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "18bd9700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as gpt2-small124M-sft.pth\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "file_name = f\"{re.sub(r'[ ()]', '', CHOOSE_MODEL) }-sft.pth\"\n",
    "torch.save(model.state_dict(), file_name)\n",
    "print(f\"Model saved as {file_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dl-env)",
   "language": "python",
   "name": "dl-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
